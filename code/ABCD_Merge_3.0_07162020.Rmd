---
title: "ABCD_Merge_3.0_07162020"
author: "Elizabeth McNeilly"
date: "7/16/2020"
output: html_document
---

#NOTE: 
- Change working directory to the location where the raw data is saved. 
#SETUP
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(plyr)
library(readr)

getwd()
# Set your data directory here.
data_directory <- "~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/test"

#Convert .txt files to .csv format. 
setwd(data_directory)
filelist = list.files(pattern = ".txt")
for (i in 1:length(filelist)){
    input<-filelist[i]
    output <- paste0(gsub("\\.txt$", "", input), ".csv")
    print(paste("Processing the file:", input))
    data = read.delim(input, header = TRUE)   
    #setwd("/Users/elizabethmcneilly/Desktop/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/test/")
    write.table(data, file=output, sep=",", col.names=TRUE, row.names=FALSE)
    #setwd("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/test/")
}


#Set Input List to the converted .csv files
setwd("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/test")
input_list = list.files(pattern = ".csv")
tables = list()

setwd("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/test")
dat_abcd_complete <- ldply(input_list, read_csv) #PUTS ALL .CSV FILES INTO ONE DATA FRAME, BUT IT DOESN'T APPEAR TO LINE UP PROPERLY ACROSS ROWS.

setwd("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/Output/")
write.csv(dat_abcd_complete, "~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/Output/dat_abcd_complete.csv")
```



#Separate Data Frames
```{r}
#THIS STEP COULD BE MORE EFFICIENT BY READING THEM ALL IN AT THE SAME TIME
#Read in data in separate data frames:

bisbas01 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/abcd_bisbas01.csv")

cbcls01 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/abcd_cbcls01.csv")

hsss01 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/abcd_hsss01.csv")


lpds01 <- read_csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/abcd_lpds01.csv")


lt01 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/abcd_lt01.csv")


mid02 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/abcd_mid02.csv")

ppdms01 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/abcd_ppdms01.csv")

ypdms01 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/abcd_ypdms01.csv")

fhxp102 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/fhxp102.csv")

midaparc03 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/midaparc03.csv")

midaparcp203 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/midaparcp203.csv")



##NOTE: This file cannot be read in for some reason. It produces an error about the final line being incomplete. It freezes my R and I have to force quit each time.

#pdem02 <- read.csv("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/DATA_RELEASE_3.0/BehaviorClinicalandMRI_csv/pdem02.csv")
```


#Cleaning
```{r}
#THIS STEP WOULD BE MADE MORE EFFICIENT WITH A LOOP.
# The first row in each spreadsheet is the element description. Lets remove those for our data tables. This information is already present in the [ABCD Data Dictionaries](https://ndar.nih.gov/data_dictionary.html?source=ABCD%2BRelease%2B2.0&submission=ALL).


bisbas01 = bisbas01[-1,]
cbcls01 = cbcls01[-1,]
hsss01 = hsss01[-1,]
lpds01 = lpds01[-1,]
lt01 = lt01[-1,]
mid02 = mid02[-1,]
ppdms01 = ppdms01[-1,]
ypdms01 = ypdms01[-1,]
fhxp102 = fhxp102[-1,]
midaparc03 = midaparc03[-1,]
midaparcp203 = midaparcp203[-1,]

#Once error is resolved, do the same to pdem02.
#pdem02


```


```{r}
# Drop columns introduced by NDA, and duplicated columns across data frames. Keep the Longitudinal Tracking data (lt01) as the anchor (Do not remove the columns from lt01.)


bisbas01 = bisbas01[,!(names(bisbas01) %in% c("collection_id", "collection_title", "subjectkey", "interview_age","interview_date","gender"))]

cbcls01 = cbcls01[,!(names(cbcls01) %in% c("collection_id", "collection_title", "subjectkey", "interview_age","interview_date","gender"))]

hsss01 = hsss01[,!(names(hsss01) %in% c("collection_id", "collection_title", "subjectkey", "interview_age","interview_date","gender"))]

lpds01 = lpds01[,!(names(lpds01) %in% c("collection_id", "collection_title", "subjectkey","interview_age","interview_date","gender"))]


mid02 = mid02[,!(names(mid02) %in% c("collection_id", "collection_title", "subjectkey", "interview_age","interview_date","gender"))]

ppdms01 = ppdms01[,!(names(ppdms01) %in% c("collection_id", "collection_title", "subjectkey", "interview_age","interview_date","gender"))]

ypdms01 = ypdms01[,!(names(ypdms01) %in% c("collection_id", "collection_title", "subjectkey", "interview_age","interview_date","gender"))]

fhxp102 = fhxp102[,!(names(fhxp102) %in% c("collection_id", "collection_title", "subjectkey", "interview_age","interview_date","gender"))]

midaparc03 = midaparc03[,!(names(midaparc03) %in% c("collection_id", "collection_title", "subjectkey","interview_age","interview_date","gender"))]

midaparcp203 = midaparcp203[,!(names(midaparcp203) %in% c("collection_id", "collection_title", "subjectkey", "interview_age","interview_date","gender"))]



#Once error is resolved, do the same to pdem02
#pdem02 = pdem02[,!(names(pdem02) %in% c("collection_id", "collection_title", "subjectkey"))]


```


#MERGING
```{r}
#Merge the individual tables into a single spreadsheet. The following loop performs repeated merging operations between pairs of spreadsheets.


t2 = list(bisbas01, cbcls01, hsss01, lpds01, lt01, mid02, ppdms01, ypdms01, fhxp102, midaparc03, midaparcp203)


while (length(t2) > 1 ) {
  print("iteration")
  access= seq(1,length(t2)-1,2)
  for (i in access) {
    bm = dim(t2[[i]])

    by.vars=c("src_subject_id","eventname")
    t2[[i]] = merge(t2[[i]], t2[[i+1]], by=by.vars, all=TRUE)

    print(paste("rows before: ", bm[1], dim(t2[[i+1]])[1], " rows after: ",dim(t2[[i]])[1], "indices: ",i,i+1," columns: ",bm[2],"+",dim(t2[[i+1]])[2], " = ",dim(t2[[i]])[2]))
  }
  # for odd number of instruments add the last spreadsheet back to the list
  if (length(t2) %% 2 != 0) access = append(access,length(t2))
  # reduce the list
  t2 = t2[access]
}
nda20 = t2[[1]]
nda20=nda20[,-which(grepl("dataset_id",colnames(nda20)))]



# As a nicety we can sort the levels of eventname by timepoint.

nda20$eventname = factor(nda20$eventname, levels(nda20$eventname)[c(2,4,1,3)])


#NOTE: Per the original merge script: The nda data frame should contain 27,368 rows (baseline: 11,875; 6 month: 8,623; 1 year: 4,951; and 18 month: 1,919)


#As a last step we can save the data in R's native file format

saveRDS(nda20, "~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/Output/nda20.rds")

names.nda20=colnames(nda20)

save(file="names.nda20.RData",names.nda20)

# Optional -- save as .csv file as well

write.csv(nda20, "~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/Output/nda20.csv", row.names = FALSE)
```

#Read data back in
```{r}
# In order to read the data back into memory use:
nda20 = readRDS("~/Desktop/Desktop_MacBookPro/Desktop_Folders/UO/ABCD_Workshop/Data_Analysis_3.0/Output/nda20.rds")

```


